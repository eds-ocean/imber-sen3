{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc3010e-7cdc-445e-8f6a-f9426778310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, gc, glob\n",
    "\n",
    "import planetary_computer\n",
    "import pystac_client\n",
    "import fsspec\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import cf_xarray, rioxarray\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from cdo import *\n",
    "cdo = Cdo()\n",
    "cdo.cleanTempDir()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib import cm\n",
    "import colormaps as cmo\n",
    "\n",
    "from cartopy import crs as ccrs\n",
    "from cartopy import feature as cf\n",
    "\n",
    "import zipfile\n",
    "\n",
    "#from rich.jupyter import print as rprint\n",
    "from rich.table import Table\n",
    "from rich.markdown import Markdown\n",
    "from rich.console import Console\n",
    "console = Console()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcad89f-d171-4a16-8405-f35be4efffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = os.path.join(os.getcwd(),\"sentinel-3_program\",\"downloaded-data\")\n",
    "result_dir = os.path.join(os.getcwd(),\"sentinel-3_program\",\"processed-data\")\n",
    "\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "cleardown = glob.glob(os.path.join(download_dir, \"*\"))\n",
    "\n",
    "for file in cleardown:\n",
    "    os.remove(file)\n",
    "\n",
    "clearres = glob.glob(os.path.join(result_dir, \"*\"))\n",
    "clearres = [f for f in clearres if \"Sen-3\" not in f]\n",
    "\n",
    "for file in clearres:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41ad24-2389-49c0-9208-e209733a4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_flags_common = ['LAND','INLAND_WATER','COASTLINE','CLOUD','CLOUD_AMBIGUOUS','CLOUD_MARGIN','INVALID','COSMETIC','SATURATED','SUSPECT','HISOLZEN','HIGHGLINT','SNOW_ICE']\n",
    "list_flags_process = ['AC_FAIL','WHITECAPS','ADJAC','RWNEG_O2','RWNEG_O3','RWNEG_O4','RWNEG_O5','RWNEG_O6','RWNEG_O7','RWNEG_O8']\n",
    "list_flags_oc4me = ['OC4ME_FAIL','TIDAL']\n",
    "list_flags_ocnn = ['OCNN_FAIL']\n",
    "\n",
    "def flag_data_fast(list_flag, flag_names, flag_values, flag_data, flag_type='WQSF'):\n",
    "    flag_bits = np.uint64()\n",
    "    if flag_type == 'SST':\n",
    "        flag_bits = np.uint8()\n",
    "    elif flag_type == 'WQSF_lsb':\n",
    "        flag_bits = np.uint32()\n",
    "    for flag in list_flag:\n",
    "        try:\n",
    "            flag_bits = flag_bits | flag_values[flag_names.index(flag)]\n",
    "        except:\n",
    "            print(flag + ' not present')\n",
    "    return (flag_data & flag_bits) > 0\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7181029-1f2b-41b4-96f0-dd083c861f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "os.system('cls' if os.name == 'nt' else 'clear') \n",
    "\n",
    "area_md = '''\n",
    "### üåè  Area of Interest\n",
    "Please input coordinates of your area of interest. The coordinates should be in **decimal format** with minus (‚ûñ) sign for south-of-equator latitude or west-of-greenwich longitude.\n",
    "'''\n",
    "# Area of interest\n",
    "console.print(Markdown(area_md))\n",
    "\n",
    "north = float(input('North point: ')) # -6.85\n",
    "south = float(input('South point: ')) # -7.95\n",
    "west = float(input('West point: ')) # 112.66\n",
    "east = float(input('East point: ')) # 114.65\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec7d589-cf2e-4764-baf7-782478dfa80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [west, south],\n",
    "            [east, south],\n",
    "            [east, north],\n",
    "            [west, north],\n",
    "            [west, south],\n",
    "        ]\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "extent = [west, east, south, north]\n",
    "bbox = [west, south, east, north]\n",
    "\n",
    "bbox_str = f'{west},{east},{south},{north}' \n",
    "\n",
    "def format_coordinate(value, is_latitude):\n",
    "    if is_latitude:\n",
    "        suffix = \"S\" if value < 0 else \"N\"\n",
    "    else:\n",
    "        suffix = \"W\" if value < 0 else \"E\"\n",
    "\n",
    "    return f\"{abs(value)}{suffix}\"\n",
    "\n",
    "north_str = format_coordinate(north, is_latitude=True)\n",
    "south_str = format_coordinate(south, is_latitude=True)\n",
    "west_str = format_coordinate(west, is_latitude=False)\n",
    "east_str = format_coordinate(east, is_latitude=False)\n",
    "\n",
    "geostr = f\"{north_str}_{south_str}_{west_str}_{east_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c6540-376d-4824-adc7-87c5ce6bf3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy dataset based on the area of interest\n",
    "resolution = 300\n",
    "resolution_degrees = resolution / 111320\n",
    "\n",
    "num_lon = int(np.ceil((east - west) / resolution_degrees)) + 1\n",
    "num_lat = int(np.ceil((north - south) / resolution_degrees)) + 1\n",
    "\n",
    "lon = np.linspace(west, east, num_lon)\n",
    "lat = np.linspace(south, north, num_lat)\n",
    "\n",
    "ds = xr.Dataset(\n",
    "    coords={\n",
    "        \"lon\": ([\"lon\"], lon),\n",
    "        \"lat\": ([\"lat\"], lat),\n",
    "    }\n",
    ")\n",
    "\n",
    "ds.lat.attrs = {\n",
    "    'units' : 'degrees_north',\n",
    "    'unit_long' : \"Degrees North\",\n",
    "    'standard_name' : \"latitude\",\n",
    "    'long_name' : \"Latitude\",\n",
    "    'axis' : 'Y'\n",
    "}\n",
    "\n",
    "ds.lon.attrs = {\n",
    "    'units' : 'degrees_east',\n",
    "    'unit_long' : \"Degrees East\",\n",
    "    'standard_name' : \"longitude\",\n",
    "    'long_name' : \"Longitude\",\n",
    "    'axis' : 'X'\n",
    "}\n",
    "\n",
    "ds[\"data\"] = ([\"lat\", \"lon\"], np.zeros((num_lat, num_lon)))\n",
    "\n",
    "ds.rio.write_crs('epsg:4326', inplace=True)\n",
    "\n",
    "ds.to_netcdf(download_dir + '/grid_data.nc')\n",
    "\n",
    "dsinput = download_dir + '/grid_data.nc'\n",
    "grids = cdo.griddes(input = dsinput)\n",
    "gridfile = os.path.join(os.getcwd(), 'gridfile.txt') \n",
    "\n",
    "with open(gridfile, 'w') as f:\n",
    "    print(\"\\n\".join(line.strip(\"'\") for line in grids), file = f)\n",
    "\n",
    "ds.close()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15089b28-6005-4f4a-bc64-2100849248ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "os.system('cls' if os.name == 'nt' else 'clear') \n",
    "\n",
    "## Time of interest\n",
    "time_md = '''\n",
    "### üïí  Time of Interest\n",
    "\n",
    "Please input the start and end of your time of interest. The dates should be in `YYYY-MM-DD` format. This program will select data available between the the times, and returned dataset time might be different due to the availability.\n",
    "'''\n",
    "\n",
    "console.print(Markdown(time_md))\n",
    "\n",
    "print()\n",
    "dtstart = input('Time start: ')\n",
    "dtend = input('Time end: ')\n",
    "\n",
    "time_of_interest = f\"{dtstart}/{dtend}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a6f8f-49c8-4e04-8990-619b3e05f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "os.system('cls' if os.name == 'nt' else 'clear') \n",
    "\n",
    "params_md = '''\n",
    "### üìä  Dataset Parameter\n",
    "\n",
    "Please select dataset parameters you want to download. \n",
    "\n",
    "1. Download geophysical parameters (chlorophyll-a and total suspended matter)\n",
    "2. Download water surface reflectances.\n",
    "'''\n",
    "\n",
    "console.print(Markdown(params_md))\n",
    "\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    parameters = int(input('Parameters: '))\n",
    "\n",
    "    if parameters == 1:\n",
    "        nick = 'geophysical-data'\n",
    "        print()\n",
    "        print('Geophysical parameters will be processed.')\n",
    "        break\n",
    "    elif parameters == 2:\n",
    "        nick = 'optical-data'\n",
    "        print()\n",
    "        print('Water surface reflectances will be processed.')\n",
    "        break\n",
    "    else:\n",
    "        print(\"You put wrong number. Please try again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30079646-bf2a-4d2d-ab07-a48e76b10550",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\", modifier=planetary_computer.sign_inplace)\n",
    "search = catalog.search(collections=[\"sentinel-3-olci-wfr-l2-netcdf\"], intersects=area_of_interest, datetime=time_of_interest)\n",
    "\n",
    "items = search.item_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78311472-da4e-470d-ab72-3b8afb6e406e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = Table(title = \"Summary\")\n",
    "\n",
    "table.add_column(\"Released\", justify=\"left\", style=\"cyan\", no_wrap=True)\n",
    "table.add_column(\"Title\", justify=\"left\", style=\"magenta\")\n",
    "\n",
    "table.add_row(f\"Area of interest\",f\"{geostr}\")\n",
    "table.add_row(f\"Time of interest\",f\"{time_of_interest}\")\n",
    "table.add_row(f\"Number of items\",f\"{len(items)}\")\n",
    "table.add_row(f\"First dataset\",f\"{items[-1].properties['datetime']}\")\n",
    "table.add_row(f\"last dataset\",f\"{items[0].properties['datetime']}\")\n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3a84b-ac56-4bb2-a12d-007a6fafbd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "\n",
    "for i in range(3, 0, -1):\n",
    "    print(f\"Process will be started in ... {i} \", end=\"\\r\", flush=True)\n",
    "    time.sleep(1) \n",
    "\n",
    "os.system('cls' if os.name == 'nt' else 'clear') \n",
    "\n",
    "for index, item in tqdm(enumerate(items, start=1), desc=\"Processing: \", total = len(items), position=0, leave=False):\n",
    "    try:\n",
    "        console.log(f'Processing data #{index} started.')\n",
    "        file_id = item.id\n",
    "    \n",
    "        date_string = item.properties['datetime']\n",
    "        timestamp = datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        \n",
    "        console.log(f'Dataset #{index}: Reading.')\n",
    "        coord_file = xr.open_dataset(fsspec.open(item.assets[\"geo-coordinates\"].href).open())\n",
    "        flags_file = xr.open_dataset(fsspec.open(item.assets[\"wqsf\"].href).open())\n",
    "        \n",
    "        flag_names = flags_file['WQSF'].flag_meanings.split(' ')\n",
    "        flag_vals = flags_file['WQSF'].flag_masks\n",
    "        flags_data = flags_file.variables['WQSF'].data\n",
    "    \n",
    "        dta = xr.Dataset()\n",
    "        dta['longitude'] = coord_file['longitude']\n",
    "        dta['latitude'] = coord_file['latitude']\n",
    "        \n",
    "        coord_file.close()\n",
    "        flags_file.close()\n",
    "        gc.collect()\n",
    "    \n",
    "        console.log(f'Dataset #{index}: Applying flags.')\n",
    "    \n",
    "        if parameters == 1:\n",
    "            keys = [\"chl-nn\",\"tsm-nn\",\"chl-oc4me\"]\n",
    "            for k in keys:\n",
    "                if not k == 'chl_oc4me':\n",
    "                    list_flags = list_flags_common + list_flags_ocnn\n",
    "                else:\n",
    "                    list_flags = list_flags_common + list_flags_process + list_flags_oc4me\n",
    "        \n",
    "                ds = xr.open_dataset(fsspec.open(item.assets[k].href).open())\n",
    "                da = ds[[var for var in ds.variables if \"_err\" not in var][0]]\n",
    "                ds.close()\n",
    "        \n",
    "                dtarr = da.data\n",
    "        \n",
    "                flag_mask = flag_data_fast(list_flags, flag_names, flag_vals, flags_data, flag_type='WQSF')\n",
    "                \n",
    "                flagged = np.where(flag_mask, np.nan, dtarr)\n",
    "                \n",
    "                dta[str(k)] = xr.DataArray(flagged, dims=('rows','columns'))\n",
    "                dta[str(k)].attrs = da.attrs\n",
    "        \n",
    "                del ds\n",
    "                del da\n",
    "                del dtarr\n",
    "        \n",
    "        elif parameters == 2:\n",
    "            keys = ['Oa01-reflectance','Oa02-reflectance','Oa03-reflectance','Oa04-reflectance','Oa05-reflectance','Oa06-reflectance','Oa07-reflectance','Oa08-reflectance','Oa09-reflectance','Oa10-reflectance','Oa11-reflectance','Oa12-reflectance','Oa16-reflectance','Oa17-reflectance','Oa18-reflectance','Oa21-reflectance']\n",
    "            list_flags = list_flags_common + list_flags_process\n",
    "            for k in keys:\n",
    "                ds = xr.open_dataset(fsspec.open(item.assets[k].href).open())\n",
    "                da = ds[[var for var in ds.variables if \"_err\" not in var][0]]\n",
    "                ds.close()\n",
    "        \n",
    "                dtarr = da.data\n",
    "        \n",
    "                flag_mask = flag_data_fast(list_flags, flag_names, flag_vals, flags_data, flag_type='WQSF')\n",
    "                \n",
    "                flagged = np.where(flag_mask, np.nan, dtarr)\n",
    "                \n",
    "                dta[str(k)] = xr.DataArray(flagged, dims=('rows','columns'))\n",
    "                dta[str(k)].attrs = da.attrs\n",
    "        \n",
    "                del ds\n",
    "                del da\n",
    "                del dtarr\n",
    "        \n",
    "        dta = dta.set_coords(['latitude','longitude'])\n",
    "        dta = dta.expand_dims(dim={\"time\":[timestamp]}, axis=0)\n",
    "    \n",
    "        console.log(f'Dataset #{index}: Subsetting.')\n",
    "    \n",
    "        reggrid = cdo.sellonlatbox(bbox_str, input = dta, returnXDataset = True)\n",
    "        \n",
    "        comp = dict(zlib=True, _FillValue=-99999.0, complevel=4)\n",
    "        encoding = {var: comp for var in reggrid.data_vars}\n",
    "        \n",
    "        reggrid.to_netcdf(\n",
    "            os.path.join(download_dir , file_id + f'_{nick}.nc'),\n",
    "            format='NETCDF4', \n",
    "            unlimited_dims=['time'],\n",
    "            encoding=encoding\n",
    "        )\n",
    "        \n",
    "        dta.close()\n",
    "        del reggrid\n",
    "        cdo.cleanTempDir()\n",
    "        gc.collect()\n",
    "    \n",
    "        console.log(f'Dataset #{index}: Regridding.')\n",
    "    \n",
    "        dataset = xr.open_dataset(os.path.join(download_dir , file_id + f'_{nick}.nc'), decode_coords=\"all\")\n",
    "        dataset = dataset.cf.add_bounds(['latitude','longitude'])\n",
    "        \n",
    "        reggridded = cdo.remapcon(gridfile, input = dataset, returnXDataset = True)\n",
    "        \n",
    "        comp = dict(zlib=True, _FillValue=-99999.0, complevel=4)\n",
    "        encoding = {var: comp for var in reggridded.data_vars}\n",
    "        \n",
    "        reggridded.to_netcdf(\n",
    "            os.path.join(result_dir , file_id + f'_{nick}.nc'),\n",
    "            format='NETCDF4', \n",
    "            unlimited_dims=['time'],\n",
    "            encoding=encoding\n",
    "        )\n",
    "    \n",
    "        dataset.close()\n",
    "        del reggridded\n",
    "        cdo.cleanTempDir()\n",
    "        gc.collect()\n",
    "    \n",
    "        console.log(f'Dataset #{index}: Finished')\n",
    "    \n",
    "        time.sleep(0.5)\n",
    "        os.system('cls' if os.name == 'nt' else 'clear') \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6202bf-2ff1-4b80-816d-a4aa7439decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(f'Combining dataset.')\n",
    "\n",
    "files = glob.glob(os.path.join(result_dir , f'S3*{nick}.nc'))\n",
    "ds = xr.open_mfdataset(files)\n",
    "\n",
    "ds_day = ds.resample(time=\"D\").mean()\n",
    "\n",
    "ds.close()\n",
    "gc.collect()\n",
    "\n",
    "console.log(f'Saving result.')\n",
    "\n",
    "ds_day.to_netcdf(\n",
    "    os.path.join(result_dir, f'Sen-3_{str(ds.time[0].data)[0:10]}_{str(ds.time[-1].data)[0:10]}_{geostr}_{nick}.nc'),\n",
    "    format = 'NETCDF4', \n",
    "    encoding = {var: comp for var in ds_day.data_vars}\n",
    ")\n",
    "\n",
    "console.log(f'All process done! üòé')\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "md_end = f\"\"\"\n",
    "Processing requested dataset succesfull. You can now download your data by accessing this path `{os.path.join(result_dir, f'Sen-3_{str(ds.time[0].data)[0:10]}_{str(ds.time[-1].data)[0:10]}_{geostr}_{nick}.nc')}` from the sidebar.\n",
    "\"\"\"\n",
    "\n",
    "console.print(Markdown(md_end))\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c2b5e-e97b-48fd-99d8-90ea018aee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_delete = glob.glob(os.path.join(result_dir, \"*.nc\"))\n",
    "files_to_delete = [f for f in files_to_delete if \"Sen-3\" not in f]\n",
    "\n",
    "for file in files_to_delete:\n",
    "    os.remove(file)\n",
    "\n",
    "#display(ds)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89f20eb5-0473-4b3f-ba5c-7f9dd7c5bfdc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
