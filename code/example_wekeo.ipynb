{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db4f31f-5f7b-4798-88f0-aec9da408695",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m cdo \u001b[38;5;241m=\u001b[39m Cdo()\n\u001b[1;32m     15\u001b[0m cdo\u001b[38;5;241m.\u001b[39mcleanTempDir()\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import os, shutil, gc, glob\n",
    "\n",
    "import hda\n",
    "from getpass import getpass\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import cf_xarray, rioxarray\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from cdo import *\n",
    "cdo = Cdo()\n",
    "cdo.cleanTempDir()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib import cm\n",
    "import colormaps as cmo\n",
    "\n",
    "from cartopy import crs as ccrs\n",
    "from cartopy import feature as cf\n",
    "\n",
    "import zipfile\n",
    "\n",
    "from rich.jupyter import print as rprint\n",
    "from rich.table import Table\n",
    "from rich.markdown import Markdown\n",
    "from rich.console import Console\n",
    "console = Console()\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0cd68c-6a66-4a80-a92c-2f9fc0db5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = os.path.join(os.getcwd(),\"sentinel-3_program\",\"downloaded-data\")\n",
    "result_dir = os.path.join(os.getcwd(),\"sentinel-3_program\",\"processed-data\")\n",
    "\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "cleardown = glob.glob(os.path.join(download_dir, \"*\"))\n",
    "\n",
    "for file in cleardown:\n",
    "    os.remove(file)\n",
    "\n",
    "clearres = glob.glob(os.path.join(result_dir, \"*\"))\n",
    "clearres = [f for f in clearres if \"Sen-3\" not in f]\n",
    "\n",
    "for file in clearres:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b1641-3a92-4cca-b319-6a35b5f633ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_flags_common = ['LAND','INLAND_WATER','COASTLINE','CLOUD','CLOUD_AMBIGUOUS','CLOUD_MARGIN','INVALID','COSMETIC','SATURATED','SUSPECT','HISOLZEN','HIGHGLINT','SNOW_ICE']\n",
    "list_flags_process = ['AC_FAIL','WHITECAPS','ADJAC','RWNEG_O2','RWNEG_O3','RWNEG_O4','RWNEG_O5','RWNEG_O6','RWNEG_O7','RWNEG_O8']\n",
    "list_flags_oc4me = ['OC4ME_FAIL','TIDAL']\n",
    "list_flags_ocnn = ['OCNN_FAIL']\n",
    "\n",
    "def flag_data_fast(list_flag, flag_names, flag_values, flag_data, flag_type='WQSF'):\n",
    "    flag_bits = np.uint64()\n",
    "    if flag_type == 'SST':\n",
    "        flag_bits = np.uint8()\n",
    "    elif flag_type == 'WQSF_lsb':\n",
    "        flag_bits = np.uint32()\n",
    "    for flag in list_flag:\n",
    "        try:\n",
    "            flag_bits = flag_bits | flag_values[flag_names.index(flag)]\n",
    "        except:\n",
    "            print(flag + 'not present')\n",
    "    return (flag_data & flag_bits) > 0\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ad370e-f5a9-448e-89d7-3e237005f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('cls' if os.name == 'nt' else 'clear') \n",
    "\n",
    "intro_md = '''\n",
    "# Welcome to Sentinel-3 OLCI Biogeochemical Data Access Program\n",
    "\n",
    "This program is developed by Edwards Taufiqurrahman and the Integrated Marine Biosphere Research Group, Research Centre for Oceanography, National Research and Innovation Agency, Indonesia.\n",
    "\n",
    "At first, you will be asked the WEkEO `Username` and `Password` and data that you need. Therefore, before start, please make sure that you have a WEkEO Account (you can create one from this link: [https://www.wekeo.eu/register](https://www.wekeo.eu/register)) and you should already know some information about data that you need.\n",
    "\n",
    "### Enter your WEkEO Credential\n",
    "'''\n",
    "\n",
    "rprint(Markdown(intro_md))\n",
    "\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user = input(\"Enter your WEkEO username: \")\n",
    "        passw = getpass(\"Enter your WEkEO password: \")\n",
    "        c = hda.Client(hda.Configuration(user=user, password=passw), progress=True, max_workers=1)\n",
    "        print()\n",
    "        print(f\"Login successfull!. Your token is {c.token}.\")\n",
    "        break\n",
    "    except KeyError:\n",
    "        print()\n",
    "        print('You entered wrong username and/or password.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346caad-ce0e-4178-a182-9e6203c2ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "os.system('cls' if os.name == 'nt' else 'clear') \n",
    "\n",
    "sat_md_1 = '''\n",
    "### Enter Satellite Parameters\n",
    "\n",
    "Sentinel-3 program have 2 satellites: Sentinel-3A (launched 16 February 2016) and Sentinel-3B (launched 25 April 2018).\n",
    "\n",
    "However, the Sentinel-3 Level 2 dataset in WEkEO are available in two type:\n",
    "\n",
    "1. `EO:EUM:DAT:SENTINEL-3:0556` &rarr; Reprocessed dataset (25 April 2016 - 28 April 2021)\n",
    "2. `EO:EUM:DAT:SENTINEL-3:OL_2_WFR___` &rarr; (5 July 2017 - recent)\n",
    "\n",
    "#### Enter the satellite designation (`A` or `B`):\n",
    "\n",
    "- `A` = Sentinel-3A\n",
    "- `B` = Sentinel-3B\n",
    "\n",
    "Leave it blank if you want both Sentinel-3A and Sentinel-3B queried.\n",
    "\n",
    "'''\n",
    "\n",
    "rprint(Markdown(sat_md_1))\n",
    "print()\n",
    "\n",
    "sat_nm = input(\"Satellite name: \")\n",
    "\n",
    "print()\n",
    "\n",
    "if sat_nm == 'a' or sat_nm == 'A':\n",
    "    sat = 'Sentinel-3A'\n",
    "    print()\n",
    "elif sat_nm == 'b' or sat_nm == 'B':\n",
    "    sat = 'Sentinel-3B'\n",
    "    print()\n",
    "else:\n",
    "    sat = ''\n",
    "    print()\n",
    "\n",
    "sat_md_2 = '''\n",
    "\n",
    "#### Enter Sentinel-3 dataset ID (`1` or `2`)\n",
    "\n",
    "1. EO:EUM:DAT:SENTINEL-3:0556\n",
    "2. EO:EUM:DAT:SENTINEL-3:OL_2_WFR___\n",
    "'''\n",
    "\n",
    "rprint(Markdown(sat_md_2))\n",
    "\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    sat_id = int(input('Satellite ID: '))\n",
    "\n",
    "    if sat_id == 1:\n",
    "        dataset_id = 'EO:EUM:DAT:SENTINEL-3:0556'\n",
    "        print()\n",
    "        break\n",
    "    elif sat_id == 2:\n",
    "        dataset_id = 'EO:EUM:DAT:SENTINEL-3:OL_2_WFR___'\n",
    "        print()\n",
    "        break\n",
    "    else:\n",
    "        print()\n",
    "        rprint(\"You put wrong number. Please try again!\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ca484-41d6-4a00-839d-421daaccdf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "os.system('cls' if os.name == 'nt' else 'clear') \n",
    "\n",
    "area_md = '''\n",
    "Please input your area of interest. The coordinates should be in **decimal format** with minus (`-`) sign for south-of-equator latitude or west-of-greenwich longitude.\n",
    "'''\n",
    "# Area of interest\n",
    "rprint(Markdown(area_md))\n",
    "\n",
    "north = float(input('North point: ')) # -6.85\n",
    "south = float(input('South point: ')) # -7.95\n",
    "west = float(input('West point: ')) # 112.66\n",
    "east = float(input('East point: ')) # 114.65\n",
    "\n",
    "bbox = [west, south, east, north]\n",
    "extent = [west, east, north, south]\n",
    "bbox_str = f'{west},{east},{south},{north}' \n",
    "\n",
    "def format_coordinate(value, is_latitude):\n",
    "    if is_latitude:\n",
    "        suffix = \"S\" if value < 0 else \"N\"\n",
    "    else:\n",
    "        suffix = \"W\" if value < 0 else \"E\"\n",
    "\n",
    "    return f\"{abs(value)}{suffix}\"\n",
    "\n",
    "north_str = format_coordinate(north, is_latitude=True)\n",
    "south_str = format_coordinate(south, is_latitude=True)\n",
    "west_str = format_coordinate(west, is_latitude=False)\n",
    "east_str = format_coordinate(east, is_latitude=False)\n",
    "\n",
    "geostr = f\"{north_str}_{south_str}_{west_str}_{east_str}\"\n",
    "\n",
    "print(geostr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd28f4-4839-4aef-a7b2-8adc128121c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy dataset based on the area of interest\n",
    "resolution = 300\n",
    "resolution_degrees = resolution / 111320\n",
    "\n",
    "num_lon = int(np.ceil((east - west) / resolution_degrees)) + 1\n",
    "num_lat = int(np.ceil((north - south) / resolution_degrees)) + 1\n",
    "\n",
    "lon = np.linspace(west, east, num_lon)\n",
    "lat = np.linspace(south, north, num_lat)\n",
    "\n",
    "ds = xr.Dataset(\n",
    "    coords={\n",
    "        \"lon\": ([\"lon\"], lon),\n",
    "        \"lat\": ([\"lat\"], lat),\n",
    "    }\n",
    ")\n",
    "\n",
    "ds.lat.attrs = {\n",
    "    'units' : 'degrees_north',\n",
    "    'unit_long' : \"Degrees North\",\n",
    "    'standard_name' : \"latitude\",\n",
    "    'long_name' : \"Latitude\",\n",
    "    'axis' : 'Y'\n",
    "}\n",
    "\n",
    "ds.lon.attrs = {\n",
    "    'units' : 'degrees_east',\n",
    "    'unit_long' : \"Degrees East\",\n",
    "    'standard_name' : \"longitude\",\n",
    "    'long_name' : \"Longitude\",\n",
    "    'axis' : 'X'\n",
    "}\n",
    "\n",
    "ds[\"data\"] = ([\"lat\", \"lon\"], np.zeros((num_lat, num_lon)))\n",
    "\n",
    "ds.rio.write_crs('epsg:4326', inplace=True)\n",
    "\n",
    "ds.to_netcdf(download_dir + '/grid_data.nc')\n",
    "\n",
    "dsinput = download_dir + '/grid_data.nc'\n",
    "grids = cdo.griddes(input = dsinput)\n",
    "gridfile = os.path.join(os.getcwd(), 'gridfile.txt') \n",
    "\n",
    "with open(gridfile, 'w') as f:\n",
    "    print(\"\\n\".join(line.strip(\"'\") for line in grids), file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ea1cb-6682-4f80-adf0-a86ef6a23c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "os.system('cls' if os.name == 'nt' else 'clear') \n",
    "\n",
    "## Time of interest\n",
    "time_md = '''\n",
    "### Time of Interest\n",
    "\n",
    "Please input the start date and end date of your interest. The dates should be in `YYYY-MM-DD` format. Only use the time period suitable for your selected dataset.\n",
    "'''\n",
    "\n",
    "rprint(Markdown(time_md))\n",
    "\n",
    "print()\n",
    "dtstart = input('Time start: ')\n",
    "dtend = input('Time end: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108cbd97-b9ef-4eef-adeb-b0c3f5c9528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "os.system('cls' if os.name == 'nt' else 'clear') \n",
    "\n",
    "params_md = '''\n",
    "Please select what parameters you want to download. \n",
    "\n",
    "1. Download geophysical (chlorophyll-a and total suspended matter)\n",
    "2. Download water surface reflectances.\n",
    "'''\n",
    "rprint(Markdown(params_md))\n",
    "\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    parameters = int(input('Parameters: '))\n",
    "\n",
    "    if parameters == 1:\n",
    "        nick = 'geophysical-data'\n",
    "        print()\n",
    "        print('Geophysical data will be processed.')\n",
    "        break\n",
    "    elif parameters == 2:\n",
    "        nick = 'optical-data'\n",
    "        print()\n",
    "        print('Reflectance data will be processed.')\n",
    "        break\n",
    "    else:\n",
    "        print(\"You put wrong number. Please try again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e29c2d-e074-446a-867f-ed492a4760a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "os.system('cls' if os.name == 'nt' else 'clear') \n",
    "\n",
    "resume_md = '''\n",
    "### Data Query\n",
    "\n",
    "Below is the resume of data query based on your input.\n",
    "'''\n",
    "\n",
    "query = {\n",
    "  \"dataset_id\": dataset_id, \n",
    "  \"dtstart\": dtstart,\n",
    "  \"dtend\": dtend,\n",
    "  \"bbox\": bbox,\n",
    "  \"sat\": sat,\n",
    "  \"type\": \"OL_2_WFR___\",\n",
    "  \"timeliness\": \"NT\"\n",
    "}\n",
    "\n",
    "query_tab = Table(title=\"Search Query\")\n",
    "query_tab.add_column('Parameter', style='cyan')\n",
    "query_tab.add_column('Value', style='bright_green')\n",
    "\n",
    "for col1, col2 in query.items():\n",
    "    query_tab.add_row(str(col1), str(col2))\n",
    "\n",
    "\n",
    "rprint(Markdown(resume_md))\n",
    "rprint(query_tab)\n",
    "\n",
    "time.sleep(0.5)\n",
    "\n",
    "search_result = c.search(query)\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e02c3-0139-47dc-ad47-14ee20bd644f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print()\n",
    "\n",
    "for i in range(3, 0, -1):\n",
    "    print(f\"Process will be started in ... {i} \", end=\"\\r\", flush=True)\n",
    "    time.sleep(1) \n",
    "\n",
    "os.system('cls' if os.name == 'nt' else 'clear') \n",
    "\n",
    "for index, result in tqdm(enumerate(search_result.results, start=0), desc=\"Processing: \", total = len(search_result.results), position=0, leave=False):\n",
    "    try:\n",
    "        console.log(f'Processing data #{index} started.')\n",
    "        file_id = result['id']\n",
    "    \n",
    "        start = datetime.strptime(result['properties']['startdate'], '%Y-%m-%dT%H:%M:%S%fZ')\n",
    "        end = datetime.strptime(result['properties']['enddate'], '%Y-%m-%dT%H:%M:%S%fZ')\n",
    "        timestamp = start + (end - start) / 2\n",
    "    \n",
    "        console.log(f'Downloading data.')\n",
    "        search_result[index].download()\n",
    "    \n",
    "    \n",
    "        with zipfile.ZipFile(file_id + '.zip', 'r') as zip_ref:\n",
    "            console.log(f'Extracting data.')\n",
    "            zip_ref.extractall(download_dir)\n",
    "            os.remove(file_id + '.zip')\n",
    "    \n",
    "        console.log(f'Applying mask to data.')\n",
    "        \n",
    "        geo_coords = xr.open_dataset(os.path.join(download_dir, file_id, 'geo_coordinates.nc'))\n",
    "        \n",
    "        flag_file = xr.open_dataset(os.path.join(download_dir, file_id, 'wqsf.nc'))\n",
    "        flag_names = flag_file['WQSF'].flag_meanings.split(' ') #flag names\n",
    "        flag_vals = flag_file['WQSF'].flag_masks #flag bit values\n",
    "        flags_data = flag_file.variables['WQSF'].data\n",
    "            \n",
    "        dta = xr.Dataset()\n",
    "        dta['longitude'] = geo_coords['longitude']\n",
    "        dta['latitude'] = geo_coords['latitude']\n",
    "        \n",
    "        geo_coords.close()\n",
    "        flag_file.close()\n",
    "        gc.collect()\n",
    "    \n",
    "        if parameters == 1:\n",
    "            keys = [\"chl_nn\",\"tsm_nn\",\"chl_oc4me\"]\n",
    "            for k in keys:\n",
    "                if not k == 'chl_oc4me':\n",
    "                    list_flags = list_flags_common + list_flags_ocnn\n",
    "                else:\n",
    "                    list_flags = list_flags_common + list_flags_process + list_flags_oc4me\n",
    "        \n",
    "                ds = xr.open_dataset(os.path.join(download_dir, file_id, f'{k}.nc'))\n",
    "                dtarr = ds[str(k.upper())].data\n",
    "                flag_mask = flag_data_fast(list_flags, flag_names, flag_vals, flags_data, flag_type='WQSF')\n",
    "                \n",
    "                flagged = np.where(flag_mask, np.nan, dtarr)\n",
    "                \n",
    "                dta[str(k)] = xr.DataArray(flagged, dims=('rows','columns'))\n",
    "                dta[str(k)].attrs = ds[str(k.upper())].attrs\n",
    "        elif parameters == 2:\n",
    "            keys = ['Oa01_reflectance','Oa02_reflectance','Oa03_reflectance','Oa04_reflectance','Oa05_reflectance','Oa06_reflectance','Oa07_reflectance','Oa08_reflectance','Oa09_reflectance','Oa10_reflectance','Oa11_reflectance','Oa12_reflectance','Oa16_reflectance','Oa17_reflectance','Oa18_reflectance','Oa21_reflectance']\n",
    "            list_flags = list_flags_common + list_flags_process\n",
    "            for k in keys:\n",
    "                ds = xr.open_dataset(os.path.join(download_dir, file_id, f'{k}.nc'))\n",
    "                dtarr = ds[str(k)].data\n",
    "                flag_mask = flag_data_fast(list_flags, flag_names, flag_vals, flags_data, flag_type='WQSF')\n",
    "                \n",
    "                flagged = np.where(flag_mask, np.nan, dtarr)\n",
    "                \n",
    "                dta[str(k)] = xr.DataArray(flagged, dims=('rows','columns'))\n",
    "                dta[str(k)].attrs = ds[str(k)].attrs\n",
    "        \n",
    "        dta = dta.set_coords(['latitude','longitude'])\n",
    "        dta = dta.expand_dims(dim={\"time\":[timestamp]}, axis=0)\n",
    "    \n",
    "        console.log(f'Subsetting data.')\n",
    "    \n",
    "        reggrid = cdo.sellonlatbox(bbox_str, input = dta, returnXDataset = True)\n",
    "        \n",
    "        comp = dict(zlib=True, _FillValue=-99999.0, complevel=4)\n",
    "        encoding = {var: comp for var in reggrid.data_vars}\n",
    "        \n",
    "        reggrid.to_netcdf(\n",
    "            os.path.join(download_dir , file_id + f'_{nick}.nc'),\n",
    "            format='NETCDF4', \n",
    "            unlimited_dims=['time'],\n",
    "            encoding=encoding\n",
    "        )\n",
    "        \n",
    "        cdo.cleanTempDir()\n",
    "    \n",
    "        dataset = xr.open_dataset(os.path.join(download_dir , file_id + f'_{nick}.nc'), decode_coords=\"all\")\n",
    "        dataset = dataset.cf.add_bounds(['latitude','longitude'])\n",
    "    \n",
    "        reggridded = cdo.remapcon(gridfile, input = dataset, returnXDataset = True)\n",
    "        \n",
    "        comp = dict(zlib=True, _FillValue=-99999.0, complevel=4)\n",
    "        encoding = {var: comp for var in reggridded.data_vars}\n",
    "        \n",
    "        reggridded.to_netcdf(\n",
    "            os.path.join(result_dir , file_id + f'_{nick}.nc'),\n",
    "            format='NETCDF4', \n",
    "            unlimited_dims=['time'],\n",
    "            encoding=encoding\n",
    "        )\n",
    "        \n",
    "        cdo.cleanTempDir()\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        for allitem in os.listdir(download_dir):\n",
    "            path = os.path.join(download_dir,allitem)\n",
    "            if os.path.isfile(path):\n",
    "                os.remove(path)\n",
    "            elif os.path.isdir(path):\n",
    "                shutil.rmtree(path)\n",
    "    \n",
    "        console.log(f'#{index + 1} data processing done.')\n",
    "    \n",
    "        del dta\n",
    "        del dataset\n",
    "        del reggridded\n",
    "    \n",
    "        time.sleep(1)\n",
    "        os.system('cls' if os.name == 'nt' else 'clear') \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "        #rprint(\"Processing done! :sunglasses: Will continue with creating timeseries dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7338952-75dd-4d65-8d43-7c841d1b9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(result_dir , f'S3*{nick}.nc'))\n",
    "ds = xr.open_mfdataset(files, decode_coords=\"all\")\n",
    "\n",
    "ds_day = ds.resample(time=\"D\").mean()\n",
    "\n",
    "ds_day.to_netcdf(\n",
    "    os.path.join(result_dir, f'Sen-3_{str(ds.time[0].data)[0:10]}_{str(ds.time[-1].data)[0:10]}_{geostr}_{nick}.nc'),\n",
    "    format = 'NETCDF4', \n",
    "    encoding = {var: comp for var in ds_day.data_vars}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f21379-c86e-4b8b-9b79-0a9dd400046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_span = (ds_day.time[-1] - ds_day.time[0]).values / np.timedelta64(1,'D') \n",
    "\n",
    "if time_span >= 365:\n",
    "    ds_month = ds.resample(time=\"MS\").mean()\n",
    "    ds_month.to_netcdf(\n",
    "        os.path.join(result_dir, f'Sen-3_{str(ds.time[0].data)[0:10]}_{str(ds.time[-1].data)[0:10]}_{nick}_monthly.nc'),\n",
    "        encoding = {var: comp for var in ds_month.data_vars}\n",
    "    )\n",
    "    print(ds_month)\n",
    "    if time_span >= 730:\n",
    "        ds_season = ds.resample(time=\"QS-DEC\").mean()\n",
    "        ds_season.to_netcdf(\n",
    "            os.path.join(result_dir, f'Sen-3_{str(ds.time[0].data)[0:10]}_{str(ds.time[-1].data)[0:10]}_{nick}_seasonal.nc'),\n",
    "            encoding = {var: comp for var in ds_season.data_vars}\n",
    "        )\n",
    "        print(ds_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d65eb-2a8d-4841-8e3f-65ef5122272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_delete = glob.glob(os.path.join(result_dir, \"*.nc\"))\n",
    "files_to_delete = [f for f in files_to_delete if \"Sen-3\" not in f]\n",
    "\n",
    "for file in files_to_delete:\n",
    "    os.remove(file)\n",
    "\n",
    "#display(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c322e8ca-84f5-4407-ab8e-44158b578d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4755163-9406-45dd-8617-f26ff80727ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sen3_wk",
   "language": "python",
   "name": "sen3_wk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
